Overriding model.yaml nc=80 with nc=2
                 from  n    params  module                                  arguments
  0                -1  1      5280  models.common.Focus                     [3, 48, 3]
  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]
  2                -1  1     65280  models.common.C3                        [96, 96, 2]
  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]
  4                -1  1    629760  models.common.C3                        [192, 192, 6]
  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]
  6                -1  1   2512896  models.common.C3                        [384, 384, 6]
  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]
  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]
  9                -1  1   4134912  models.common.C3                        [768, 768, 2, False]
 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]
 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]
 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]
 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]
 24      [17, 20, 23]  1     28287  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Model Summary: 391 layers, 21060447 parameters, 21060447 gradients, 50.4 GFLOPs
Transferred 500/506 items from yolov5m.pt
Scaled weight_decay = 0.0005
Optimizer groups: 86 .bias, 86 conv.weight, 83 other
[34m[1malbumentations: [39m[22mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed
[34m[1mtrain: [39m[22mScanning '../lisa/labels/train.cache' images and labels... 2437 found, 240 missing, 0 empty, 0 corrupted: 100% 2677/2677 [00:00<00:00, 18744827.73it/s]












































































































































































































































































































































































































































































































































































[34m[1mtrain: [39m[22mCaching images (2.0GB): 100% 2677/2677 [18:36<00:00,  2.40it/s]
[34m[1mval: [39m[22mScanning '../lisa/labels/val.cache' images and labels... 332 found, 0 missing, 0 empty, 0 corrupted: 100% 332/332 [00:00<00:00, 522517.42it/s]


































































[34m[1mval: [39m[22mCaching images (0.3GB): 100% 332/332 [02:12<00:00,  2.51it/s]
Plotting labels...
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Image sizes 640 train, 640 val
Using 2 dataloader workers
Logging results to runs/train/exp2
Starting training for 1000 epochs...
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size
  0% 0/168 [00:00<?, ?it/s]








































     0/999     6.03G   0.09876     0.018   0.02631    0.1431         5       640: 100% 168/168 [01:21<00:00,  2.06it/s]

               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:03<00:00,  3.63it/s]
                 all        332        332    0.00419      0.158     0.0029   0.000685
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size




































     1/999     7.66G   0.07377   0.01423   0.02495    0.1129         5       640: 100% 168/168 [01:15<00:00,  2.22it/s]


               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:02<00:00,  3.69it/s]
                 all        332        332      0.053      0.366     0.0453     0.0145
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size



     2/999     7.66G   0.07208   0.01119   0.02286    0.1061        16       640:  10% 17/168 [00:07<01:08,  2.22it/s]Exception in thread Thread-19:
Traceback (most recent call last):
  File "/usr/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py", line 28, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py", line 289, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.7/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.7/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.7/multiprocessing/connection.py", line 492, in Client
    c = SocketClient(address)
  File "/usr/lib/python3.7/multiprocessing/connection.py", line 620, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "train.py", line 658, in <module>
    main(opt)
  File "train.py", line 556, in main
    train(opt.hyp, opt, device)
  File "train.py", line 360, in train
    f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1])
KeyboardInterrupt