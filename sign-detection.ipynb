{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/125273437-35b3fc00-e30d-11eb-9079-46f313325424.png\"></a>\n",
    "\n",
    "Based from the **official YOLOv5 ðŸš€ notebook** authored by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QoRX-tKYtrh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\Desktop\\Test Detection\\sign-detection\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd ./yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.11.0+cpu (CPU)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# Inference\n",
    "Run cells in order\n",
    "\n",
    "1.   Parameters\n",
    "> Where user can adjust settings for processing and OCR\n",
    "2.   Functions\n",
    "> Functions used in other cells\n",
    "3.   Detection\n",
    "> YOLOv5 detection to create labels\n",
    "4.   Process labels\n",
    "> * Processes the labels in a multi-step process to allow smoother labeling in video\n",
    "> * Refer to cell for more information\n",
    "5.   OCR\n",
    "> EasyOCR to read speeds from speed limit signs and validate stop signs\n",
    "6. Generate snippet highlights (optional)\n",
    "> Creates snippets of only detections\n",
    "7.   Generate results \n",
    "> Creates a results CSV that is more readable than labels.csv (optional)\n",
    "8.   Generate videos\n",
    "> Create videos with labels (optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1mtCanKASse"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A0rdIN_PANKY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# ===== ===== ===== ===== ===== PATHS ===== ===== ===== ===== =====\n",
    "\n",
    "# Path to folder of source videos for detections\n",
    "videos_path = \"../videos\"\n",
    "\n",
    "# Path to folder for output csvs containing detection labels\n",
    "# will automatically generate\n",
    "csv_output_path = \"../csv_raw_output\"\n",
    "\n",
    "# Path to folder where post processed videos are saved\n",
    "# will automatically generate\n",
    "video_output_path = \"../videos_processed\"\n",
    "\n",
    "# Path to dataset .yaml file\n",
    "dataset_yaml = \"./data/lisa.yaml\"\n",
    "\n",
    "# Path to weights\n",
    "weights_path = \"../weights/yolov5l_200_epochs.pt\"\n",
    "\n",
    "# Path to results, set to None if you don't want to generate a new folder for all results\n",
    "# will automatically generate\n",
    "results_output_path = os.path.join(videos_path , \"results\")\n",
    "\n",
    "# Path to video snippets of only detections\n",
    "# will automatically generate\n",
    "video_snippets_path = os.path.join(videos_path , \"snippets\")\n",
    "\n",
    "\n",
    "\n",
    "# ===== ===== ===== ===== ===== DETECTION ===== ===== ===== ===== =====\n",
    "# How much to increment each frame in the detection model, 1 = source fps, 2 = half of source fps, 3 = third of source fps, etc\n",
    "frame_inc = 1\n",
    "\n",
    "\n",
    "\n",
    "# ===== ===== ===== ===== ===== PROCESSING ===== ===== ===== ===== =====\n",
    "\n",
    "# Range of frames that checks if there is an overlapping detection of the same class, if below threshold then outlier is removed\n",
    "outlier_range = 50\n",
    "\n",
    "# Max number of frames group together before not an outlier\n",
    "outlier_count = 1\n",
    "\n",
    "# Range of frames that allows a gap to be filled\n",
    "# Has to be less than outlier_range or else won't work\n",
    "gap_range = 25\n",
    "\n",
    "# Percentage of overlap required to be considered same object\n",
    "overlap_threshold = 0.001\n",
    "\n",
    "# ID range, range that groups detections together\n",
    "# Should be pretty big, since speed limit numbers don't change within a few seconds\n",
    "id_range = 100\n",
    "\n",
    "\n",
    "\n",
    "# ===== ===== ===== ===== ===== OCR ===== ===== ===== ===== =====   \n",
    "\n",
    "# Percentage of total detections required to be valid\n",
    "# If OCR makes detections at a percentage lower than total count in ID grouping, ignore grouping\n",
    "ocr_detections_threshold = 0.05\n",
    "\n",
    "# Confidence threshold for OCR\n",
    "ocr_conf_threshold = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# ===== ===== ===== ===== ===== SNIPPETS ===== ===== ===== ===== =====  \n",
    "\n",
    "# Seconds added to before and after snippet highlight as a buffer\n",
    "snippet_buffer = 3\n",
    "\n",
    "# Whether or not to automatically snippet corresponding vehicle interior videos as well\n",
    "snippet_interior = True\n",
    "\n",
    "# Creates folder for snippets sorted by classes\n",
    "snippet_split_classes = True\n",
    "\n",
    "\n",
    "\n",
    "# ===== ===== ===== ===== ===== RESULTS ===== ===== ===== ===== =====  \n",
    "\n",
    "# Whether or not results will be dependent on snippets\n",
    "# This means removing a video from the snippets folder will result in removing a row in results\n",
    "# Adding a video won't add to the results though\n",
    "results_snippets_sync = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-Ufi8RS_LQq"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vwCVdheB_I0R"
   },
   "outputs": [],
   "source": [
    "# [x1, x2, y1, y2, class, conf]\n",
    "def getOverlapArea(a, b):\n",
    "  if a[4] != b[4]:\n",
    "    return 0\n",
    "  a_area = (a[1] - a[0]) * (a[3] - a[2])\n",
    "  b_area = (b[1] - b[0]) * (b[3] - b[2])\n",
    "  maxArea = max(a_area, b_area)\n",
    "  dxa = a[1] - b[0]\n",
    "  dya = a[3] - b[2]\n",
    "  dxya = dxa * dya\n",
    "\n",
    "  dxb = b[1] - a[0]\n",
    "  dyb = b[3] - b[2]\n",
    "  dxyb = dxb * dyb\n",
    "\n",
    "  #dx = min(a[1], b[1]) - max(a[0], b[0])\n",
    "  #dy = min(a[3], b[3]) - max(a[2], b[2])\n",
    "\n",
    "  if dxya > 0 or dxyb > 0:\n",
    "    return float(max(dxyb, dxya) / maxArea)\n",
    "\n",
    "  #if (dx>=0) and (dy>=0):\n",
    "  #  area = dx*dy\n",
    "  #  return float(area / maxArea)\n",
    "  return 0\n",
    "\n",
    "# [class, x, y, width, height, confidence]\n",
    "# to and from\n",
    "# [x1, x2, y1, y2, class, conf]\n",
    "def reformat(data, video_res, toCoordinates = True):\n",
    "  if toCoordinates:\n",
    "    x1 = max(int(video_res[0] * (float(data[1]) - ((float(data[3]) / 2)))), 0)\n",
    "    x2 = min(int(video_res[0] * (float(data[1]) + ((float(data[3]) / 2)))), video_res[0])\n",
    "    y1 = max(int(video_res[1] * (float(data[2]) - ((float(data[4]) / 2)))), 0)\n",
    "    y2 = min(int(video_res[1] * (float(data[2]) + ((float(data[4]) / 2)))), video_res[1])\n",
    "    classname = label_names[int(data[0])]\n",
    "    conf = data[5]\n",
    "    reformatted = [x1, x2, y1, y2, classname, conf]\n",
    "    if len(data) > 6:\n",
    "      reformatted.append(int(data[6]))\n",
    "    return reformatted\n",
    "  width = round((data[1] - data[0]) / video_res[0], 7)\n",
    "  height = round((data[3] - data[2]) / video_res[1], 7)\n",
    "  x = round((data[0] / video_res[0]) + (width / 2), 6)\n",
    "  y = round((data[2] / video_res[1]) + (height / 2), 6)\n",
    "  classname = label_names.index(data[4])\n",
    "  conf = data[5]\n",
    "  reformatted = f\"{classname} {x} {y} {width} {height} {conf}\"\n",
    "  if len(data) > 6:\n",
    "    reformatted = reformatted + f\" {data[6]}\"\n",
    "  return reformatted\n",
    "  \n",
    "\n",
    "# Returns list of bounding boxes\n",
    "def getBoundingBoxes(detections, video_res):\n",
    "    reformatted_detections = []\n",
    "    for detection in detections:\n",
    "      data = detection.split(\" \")\n",
    "      if len(data) != 6 and len(data) != 7:\n",
    "        continue\n",
    "      reformatted_detections.append(reformat(data, video_res))\n",
    "    return reformatted_detections\n",
    "\n",
    "# Creates new bounding boxes between two bounding boxes\n",
    "def averageBoxes(box1, box2, box_distance):\n",
    "  new_boxes = []\n",
    "  for i in range(1, box_distance + 1):\n",
    "    new_box = []\n",
    "    for k in range(0, 4):\n",
    "      new_box.append(int((box2[k] - box1[k]) / box_distance * i) + box1[k])\n",
    "    new_box.append(box1[4])\n",
    "    new_box.append(min(box1[5], box2[5]))\n",
    "    new_boxes.append(new_box)\n",
    "  return new_boxes\n",
    "\n",
    "# Preprocesses image for OCR\n",
    "def preprocess(inp_image, otsu=1):\n",
    "  processed = inp_image.copy()\n",
    "\n",
    "  # Grayscale\n",
    "  processed = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Scaling up\n",
    "  basewidth = 300\n",
    "  scale = basewidth / processed.shape[1]\n",
    "  processed = cv2.resize(processed, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "  # Thresholding\n",
    "  otsu_thresh = cv2.threshold(processed, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[0]\n",
    "  otsu_thresh *= otsu\n",
    "  processed_thresh = cv2.threshold(processed, otsu_thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "  thresh_area = processed_thresh.shape[0] * processed_thresh.shape[1]\n",
    "  #print(cv2.countNonZero(processed_thresh) / thresh_area)\n",
    "\n",
    "  # Border\n",
    "  bordersize = 10\n",
    "  processed_thresh = cv2.copyMakeBorder(processed_thresh,top=bordersize,bottom=bordersize,left=bordersize,right=bordersize,borderType=cv2.BORDER_CONSTANT,value=[255, 255, 255])\n",
    "  return processed_thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_di-O02Ahls"
   },
   "source": [
    "## Detection\n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/114307955-5c7e4e80-9ae2-11eb-9f50-a90e39bee53f.png\" width=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqfwCYby7FNg"
   },
   "source": [
    "Custom trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zR9ZbuQCH7FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Done, time since start: 865.3435003757477\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import shutil\n",
    "start_time = time.time()\n",
    "\n",
    "if (os.path.exists(csv_output_path) and os.path.isdir(csv_output_path)):\n",
    "  shutil.rmtree(csv_output_path)\n",
    "os.mkdir(csv_output_path)\n",
    "\n",
    "cmd_weights_path = \"\\\"\" + weights_path + \"\\\"\"\n",
    "cmd_videos_path = \"\\\"\" + videos_path + \"\\\"\"\n",
    "cmd_csv_output_path = \"\\\"\" + csv_output_path + \"\\\"\"\n",
    "\n",
    "!python detect.py --weights {cmd_weights_path} --img 640 --conf 0.5 --source {cmd_videos_path} --save-csv {cmd_csv_output_path} --save-conf --nosave --frame-inc {frame_inc}\n",
    "print(\"Done, time since start:\", time.time() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQOqLPRTo8eR"
   },
   "source": [
    "## Processes the labels in a csv file\n",
    "Three loops through the csv\n",
    "\n",
    "\n",
    "1.   Removes outliers\n",
    "2.   Fills in empty gaps\n",
    "3.   Applies an ID to consecutively overlapping boxes\n",
    "\n",
    "Writes to labels.csv in the videos_processed directory\n",
    "\n",
    "0 = stop sign, 1 = speed limit\n",
    "\n",
    "\\[x1,x2,y1,y2,classname,confidence,id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5JebEepq9XQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20191222_171147_EF.csv\n",
      "723 Removing outlier [1046, 1920, 0, 1037, 'stop', '0.648128\\n'] 0 nearby\n",
      "1801 Removing outlier [1555, 1588, 644, 680, 'stop', '0.582084\\n'] 0 nearby\n",
      "3209 Removing outlier [744, 803, 600, 655, 'stop', '0.519109\\n'] 0 nearby\n",
      "5183 Removing outlier [1284, 1316, 680, 712, 'stop', '0.604829\\n'] 1 nearby\n",
      "5191 Removing outlier [1359, 1397, 669, 704, 'stop', '0.516333\\n'] 0 nearby\n",
      "Filling from 632 to 636\n",
      "632 Filling in gap with [1035, 1689, 252, 1033, 'stop', '0.526324\\n']\n",
      "633 Filling in gap with [1034, 1687, 254, 1032, 'stop', '0.526324\\n']\n",
      "634 Filling in gap with [1034, 1686, 255, 1032, 'stop', '0.526324\\n']\n",
      "635 Filling in gap with [1034, 1684, 257, 1032, 'stop', '0.526324\\n']\n",
      "636 Filling in gap with [1034, 1683, 258, 1031, 'stop', '0.526324\\n']\n",
      "Filling from 638 to 638\n",
      "638 Filling in gap with [1038, 1695, 247, 1033, 'stop', '0.530543\\n']\n",
      "Filling from 640 to 642\n",
      "640 Filling in gap with [1038, 1702, 238, 1033, 'stop', '0.530543\\n']\n",
      "641 Filling in gap with [1038, 1700, 241, 1033, 'stop', '0.530543\\n']\n",
      "642 Filling in gap with [1038, 1698, 243, 1033, 'stop', '0.530543\\n']\n",
      "Filling from 644 to 650\n",
      "644 Filling in gap with [1042, 1734, 223, 894, 'stop', '0.564645\\n']\n",
      "645 Filling in gap with [1041, 1730, 225, 912, 'stop', '0.564645\\n']\n",
      "646 Filling in gap with [1041, 1726, 227, 929, 'stop', '0.564645\\n']\n",
      "647 Filling in gap with [1040, 1722, 229, 947, 'stop', '0.564645\\n']\n",
      "648 Filling in gap with [1040, 1718, 231, 964, 'stop', '0.564645\\n']\n",
      "649 Filling in gap with [1039, 1714, 233, 981, 'stop', '0.564645\\n']\n",
      "650 Filling in gap with [1039, 1710, 235, 999, 'stop', '0.564645\\n']\n",
      "Filling from 652 to 662\n",
      "652 Filling in gap with [1044, 1770, 194, 919, 'stop', '0.564645\\n']\n",
      "653 Filling in gap with [1043, 1767, 197, 916, 'stop', '0.564645\\n']\n",
      "654 Filling in gap with [1043, 1764, 199, 914, 'stop', '0.564645\\n']\n",
      "655 Filling in gap with [1043, 1761, 202, 912, 'stop', '0.564645\\n']\n",
      "656 Filling in gap with [1043, 1758, 204, 910, 'stop', '0.564645\\n']\n",
      "657 Filling in gap with [1043, 1755, 207, 908, 'stop', '0.564645\\n']\n",
      "658 Filling in gap with [1043, 1752, 209, 906, 'stop', '0.564645\\n']\n",
      "659 Filling in gap with [1042, 1749, 211, 904, 'stop', '0.564645\\n']\n",
      "660 Filling in gap with [1042, 1746, 214, 902, 'stop', '0.564645\\n']\n",
      "661 Filling in gap with [1042, 1743, 216, 900, 'stop', '0.564645\\n']\n",
      "662 Filling in gap with [1042, 1740, 219, 898, 'stop', '0.564645\\n']\n",
      "Filling from 664 to 664\n",
      "664 Filling in gap with [1050, 1779, 185, 1018, 'stop', '0.584803\\n']\n",
      "Filling from 1102 to 1104\n",
      "1102 Filling in gap with [1588, 1915, 2, 500, 'stop', '0.515511\\n']\n",
      "1103 Filling in gap with [1583, 1916, 1, 502, 'stop', '0.515511\\n']\n",
      "1104 Filling in gap with [1579, 1916, 1, 504, 'stop', '0.515511\\n']\n",
      "Filling from 1106 to 1106\n",
      "1106 Filling in gap with [1586, 1917, 2, 497, 'stop', '0.569235\\n']\n",
      "Filling from 2868 to 2868\n",
      "2868 Filling in gap with [799, 822, 667, 694, 'speedLimit', '0.560497\\n']\n",
      "Filling from 2870 to 2870\n",
      "2870 Filling in gap with [796, 819, 666, 694, 'speedLimit', '0.629448\\n']\n",
      "Filling from 2872 to 2872\n",
      "2872 Filling in gap with [793, 817, 665, 693, 'speedLimit', '0.514435\\n']\n",
      "Filling from 2874 to 2874\n",
      "2874 Filling in gap with [788, 814, 662, 693, 'speedLimit', '0.514435\\n']\n",
      "Filling from 2876 to 2876\n",
      "2876 Filling in gap with [784, 811, 657, 688, 'speedLimit', '0.622322\\n']\n",
      "Filling from 2878 to 2878\n",
      "2878 Filling in gap with [780, 807, 653, 686, 'speedLimit', '0.615063\\n']\n",
      "Filling from 2880 to 2880\n",
      "2880 Filling in gap with [775, 803, 650, 685, 'speedLimit', '0.615063\\n']\n",
      "Filling from 2882 to 2884\n",
      "2882 Filling in gap with [1378, 1405, 678, 712, 'speedLimit', '0.610238\\n']\n",
      "2883 Filling in gap with [1227, 1254, 671, 705, 'speedLimit', '0.610238\\n']\n",
      "2884 Filling in gap with [1076, 1104, 664, 698, 'speedLimit', '0.610238\\n']\n",
      "Filling from 2886 to 2886\n",
      "2886 Filling in gap with [756, 789, 643, 682, 'speedLimit', '0.610238\\n']\n",
      "Filling from 2888 to 2888\n",
      "2888 Filling in gap with [749, 784, 641, 683, 'speedLimit', '0.749189\\n']\n",
      "Filling from 2890 to 2890\n",
      "2890 Filling in gap with [741, 778, 636, 679, 'speedLimit', '0.754609\\n']\n",
      "Filling from 2892 to 2892\n",
      "2892 Filling in gap with [731, 770, 632, 679, 'speedLimit', '0.781396\\n']\n",
      "Filling from 2894 to 2894\n",
      "2894 Filling in gap with [721, 761, 629, 677, 'speedLimit', '0.781396\\n']\n",
      "Filling from 2896 to 2896\n",
      "2896 Filling in gap with [709, 750, 625, 674, 'speedLimit', '0.794194\\n']\n",
      "Filling from 2898 to 2898\n",
      "2898 Filling in gap with [694, 740, 614, 668, 'speedLimit', '0.794194\\n']\n",
      "Filling from 2900 to 2900\n",
      "2900 Filling in gap with [679, 726, 608, 665, 'speedLimit', '0.813636\\n']\n",
      "Filling from 2902 to 2902\n",
      "2902 Filling in gap with [663, 711, 601, 660, 'speedLimit', '0.829199\\n']\n",
      "Filling from 2904 to 2904\n",
      "2904 Filling in gap with [641, 694, 589, 655, 'speedLimit', '0.825459\\n']\n",
      "Filling from 2906 to 2906\n",
      "2906 Filling in gap with [617, 675, 575, 647, 'speedLimit', '0.797902\\n']\n",
      "Filling from 2908 to 2908\n",
      "2908 Filling in gap with [589, 654, 561, 641, 'speedLimit', '0.797902\\n']\n",
      "Filling from 2910 to 2910\n",
      "2910 Filling in gap with [553, 624, 543, 633, 'speedLimit', '0.840039\\n']\n",
      "Filling from 2912 to 2912\n",
      "2912 Filling in gap with [511, 592, 522, 623, 'speedLimit', '0.860435\\n']\n",
      "Filling from 2914 to 2914\n",
      "2914 Filling in gap with [459, 548, 492, 606, 'speedLimit', '0.876634\\n']\n",
      "Filling from 2916 to 2916\n",
      "2916 Filling in gap with [392, 491, 457, 586, 'speedLimit', '0.886683\\n']\n",
      "Filling from 2918 to 2918\n",
      "2918 Filling in gap with [305, 419, 412, 561, 'speedLimit', '0.709698\\n']\n",
      "5 total outliers removed, 59 spaces filled in, 3 id's assigned\n",
      "20191222_171147_EF.mp4\n",
      "id: 1 \tlabel: stop\n",
      "id: 2 \tlabel: stop\n",
      "id: 3 \tlabel: speedLimit\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "# Open yaml file to get label class data\n",
    "with open(dataset_yaml, \"r\") as yamlfile:\n",
    "  label_names = yaml.safe_load(yamlfile)[\"names\"]\n",
    "\n",
    "# Create folder\n",
    "if not os.path.exists(video_output_path):\n",
    "  os.mkdir(video_output_path)\n",
    "\n",
    "summary = {}\n",
    "# Loop through all csvs\n",
    "for source_video_name in os.listdir(videos_path):\n",
    "  csv_name = \".\".join(source_video_name.split(\".\")[:-1]) + \".csv\"\n",
    "  if not csv_name in os.listdir(csv_output_path):\n",
    "    continue\n",
    "\n",
    "  print(\"\\n\" + csv_name)\n",
    "  summary[source_video_name] = {}\n",
    "\n",
    "  # Get resolution and fps from video\n",
    "  video_name = csv_name.split(\".csv\")[0] + \".mp4\"\n",
    "  vidcap = cv2.VideoCapture(os.path.join(videos_path, video_name))\n",
    "  video_res = [int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(vidcap.get(cv2.CAP_PROP_FPS)), int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))]\n",
    "  vidcap.release()\n",
    "\n",
    "  # Convert csv to array\n",
    "  labels_array = []\n",
    "  csv_path = os.path.join(csv_output_path, csv_name)\n",
    "  with open(csv_path, \"r\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    labels_array = list(csv_reader)\n",
    "  \n",
    "  csvfile_array = []\n",
    "  for frame_count in range(video_res[3]):\n",
    "    line_append = [frame_count]\n",
    "    if len(labels_array) > 0 and len(labels_array[0]) < 2:\n",
    "      labels_array.pop(0)\n",
    "    while len(labels_array) > 0 and len(labels_array[0]) >= 2 and frame_count == int(labels_array[0][0]):\n",
    "      line_append.append(labels_array.pop(0)[1])\n",
    "    csvfile_array.append(line_append)\n",
    "\n",
    "  changes_done = [0,0]\n",
    "  \n",
    "  # Go through each frame\n",
    "  # First loop to remove outliers\n",
    "  # Only removes detections\n",
    "  for i in range(len(csvfile_array)):\n",
    "    if len(csvfile_array[i]) <= 1:\n",
    "      continue\n",
    "\n",
    "    # Create array of detections for current frame\n",
    "    curr_detections = getBoundingBoxes(csvfile_array[i][1:], video_res)\n",
    "\n",
    "    # Go through each detection and remove outliers\n",
    "    detection_count = 1\n",
    "    keep_detections = []\n",
    "    for curr_box in curr_detections:\n",
    "      nearby_count = 0\n",
    "\n",
    "      # Checks in range around it\n",
    "      for k in range(1, outlier_range + 1):\n",
    "\n",
    "        # Checks next frames\n",
    "        if i + k < len(csvfile_array):\n",
    "          if(len(csvfile_array[i+k])) > 1:\n",
    "            for next_box in getBoundingBoxes(csvfile_array[i+k][1:], video_res):\n",
    "              if getOverlapArea(curr_box, next_box) >= overlap_threshold:\n",
    "                nearby_count += 1\n",
    "              #else:\n",
    "              #  print(i, i+k, getOverlapArea(curr_box, next_box), 'no overlap')\n",
    "\n",
    "        # Checks previous frames\n",
    "        if i - k >= 0:\n",
    "          if(len(csvfile_array[i-k])) > 1:\n",
    "            for past_box in getBoundingBoxes(csvfile_array[i-k][1:], video_res):\n",
    "              if getOverlapArea(curr_box, past_box) >= overlap_threshold:\n",
    "                nearby_count += 1\n",
    "              #else:\n",
    "              #  print(i, i-k, 'no overlap')\n",
    "\n",
    "      # Removes outliers\n",
    "      if nearby_count <= outlier_count:\n",
    "        print(f\"{i} Removing outlier {curr_box} {nearby_count} nearby\")\n",
    "        csvfile_array[i].pop(detection_count)\n",
    "        changes_done[0] += 1\n",
    "      else:\n",
    "        keep_detections.append(curr_box)\n",
    "        detection_count += 1\n",
    "  # End first iteration\n",
    "\n",
    "  # Go through each frame\n",
    "  # Second loop to fill gaps\n",
    "  # Only adds detections\n",
    "  for i in range(len(csvfile_array)):\n",
    "\n",
    "    # Only does checks when there are detections on frame and a gap (empty next frame) is present\n",
    "    if len(csvfile_array[i]) <= 1:\n",
    "      continue\n",
    "\n",
    "    # Formatting from YOLO format to 4 corner coordinates\n",
    "    formatted_detections = []\n",
    "    for detection in csvfile_array[i][1:]:\n",
    "      if detection == \"\":\n",
    "        csvfile_array[i].remove(detection)\n",
    "        continue\n",
    "      d = reformat(detection.split(\" \"), video_res)\n",
    "      formatted_detections.append(f\"{d[0]};{d[1]};{d[2]};{d[3]};{d[4]};{d[5]}\")\n",
    "\n",
    "    # Prevent out of bounds errors\n",
    "    if i + 2 >= len(csvfile_array):\n",
    "      continue\n",
    "    # Create array of detections for current frame\n",
    "    curr_detections = getBoundingBoxes(csvfile_array[i][1:], video_res)\n",
    "    # Checks within a range for the next detection that overlaps\n",
    "    prev_iteration = None\n",
    "    for curr_box in curr_detections:\n",
    "      #if (not prev_iteration is None) and (getOverlapArea(curr_box, prev_iteration) >= overlap_threshold):\n",
    "      #  print(\"overlap within same frame\")\n",
    "      prev_iteration = curr_box\n",
    "      gap_present = True\n",
    "      # Checks for empty space directly in front\n",
    "      for next_box in getBoundingBoxes(csvfile_array[i+1][1:], video_res):\n",
    "        if getOverlapArea(curr_box, next_box) >= overlap_threshold:\n",
    "          gap_present = False\n",
    "\n",
    "      # Checks further in front to find if there is another overlapping frame to fill gap\n",
    "      if gap_present:\n",
    "        gap_done = False\n",
    "        for k in range(2, gap_range + 2):\n",
    "          if not gap_done and i + k < len(csvfile_array):\n",
    "            if len(csvfile_array[i+k]) > 1:\n",
    "\n",
    "              # Checks frame for a bounding box overlapping with current bounding box\n",
    "              for next_box in getBoundingBoxes(csvfile_array[i+k][1:], video_res):\n",
    "                if not gap_done:\n",
    "                  if getOverlapArea(curr_box, next_box) >= overlap_threshold:\n",
    "                    boxes_to_fill = averageBoxes(curr_box, next_box, k)\n",
    "\n",
    "                    # Fills gap with bounding boxes calculated from averages\n",
    "                    print(f\"Filling from {i+1} to {i+len(boxes_to_fill)-1}\")\n",
    "                    for x in range(1, len(boxes_to_fill)):\n",
    "                      box_to_fill = boxes_to_fill.pop()\n",
    "                      box_to_fillog = box_to_fill.copy()\n",
    "                      box_to_fill = reformat(box_to_fill, video_res, toCoordinates=False)\n",
    "                      next_boxes = getBoundingBoxes(csvfile_array[i+x][1:], video_res)\n",
    "                      future_overlap = False\n",
    "                      for b in next_boxes:\n",
    "                        if getOverlapArea(box_to_fillog, b) >= overlap_threshold:\n",
    "                          future_overlap = True\n",
    "                      if not future_overlap:\n",
    "                        csvfile_array[i+x].append(box_to_fill)\n",
    "                        print(f\"{i+x} Filling in gap with {box_to_fillog}\")\n",
    "                        changes_done[1] += 1\n",
    "                    gap_done = True\n",
    "  # End second iteration\n",
    "\n",
    "  # Go through each frame\n",
    "  # Third iteration to group detections together\n",
    "  # Only changes existing detections\n",
    "  # ID exists for the OCR\n",
    "  id = 1\n",
    "  \n",
    "  csv_array_3 = []\n",
    "  for i in range(len(csvfile_array)):\n",
    "    if len(csvfile_array[i]) <= 1:\n",
    "      csv_array_3.append(csvfile_array[i])\n",
    "      continue\n",
    "\n",
    "    # Create array of detections for current frame\n",
    "    curr_detections = getBoundingBoxes(csvfile_array[i][1:], video_res)\n",
    "    reformatted_detections = []\n",
    "    k = 1\n",
    "    for curr_box in curr_detections:\n",
    "      done = False\n",
    "      # Assigns existing ID\n",
    "      if i - 1 >= 0:\n",
    "        # Checks past boxes in given range\n",
    "        for x in range(1, id_range + 1):\n",
    "          if i - x >= 0 and not done:\n",
    "            for past_box in getBoundingBoxes(csvfile_array[i-x][1:], video_res):\n",
    "                  # Assumes speed limit signs are the same when occuring at the same time\n",
    "                  if (getOverlapArea(curr_box, past_box) >= overlap_threshold) or (past_box[4] == label_names[1] and curr_box[4] == label_names[1]):\n",
    "                    if len(past_box) > 6:\n",
    "                      reformatted_detections.append(f\"{curr_box[0]};{curr_box[1]};{curr_box[2]};{curr_box[3]};{curr_box[4]};{curr_box[5]};{past_box[6]}\")\n",
    "                      csvfile_array[i][k] = csvfile_array[i][k] + f\" {past_box[6]}\"\n",
    "                      done = True\n",
    "                      break\n",
    "      # Creates a new ID\n",
    "      if not done:\n",
    "        for next_box in getBoundingBoxes(csvfile_array[i+1][1:], video_res):\n",
    "              if getOverlapArea(curr_box, next_box) >= overlap_threshold:\n",
    "                reformatted_detections.append(f\"{curr_box[0]};{curr_box[1]};{curr_box[2]};{curr_box[3]};{curr_box[4]};{curr_box[5]};{id}\")\n",
    "                csvfile_array[i][k] = csvfile_array[i][k] + f\" {id}\"\n",
    "                done = True\n",
    "                summary[source_video_name][id] = curr_box[4]\n",
    "                id += 1\n",
    "                break\n",
    "      if not done:\n",
    "        reformatted_detections.append(f\"{curr_box[0]};{curr_box[1]};{curr_box[2]};{curr_box[3]};{curr_box[4]};{curr_box[5]};none\")\n",
    "      k += 1\n",
    "      \n",
    "    csv_array_3.append([csvfile_array[i][0]] + reformatted_detections)\n",
    "    # End third iteration   \n",
    "  print(f\"{changes_done[0]} total outliers removed, {changes_done[1]} spaces filled in, {id-1} id's assigned\")\n",
    "\n",
    "  # Create directory for video\n",
    "  video_dir_path = os.path.join(video_output_path, video_name)\n",
    "  if not os.path.exists(video_dir_path):\n",
    "    os.mkdir(video_dir_path)\n",
    "  video_labels_path = os.path.join(video_dir_path, \"labels.csv\")\n",
    "  if os.path.exists(video_labels_path):\n",
    "    os.remove(video_labels_path)\n",
    "\n",
    "  # Writes labels into a csv file\n",
    "  with open(video_labels_path, \"w\", newline='') as new_csv:\n",
    "    csv_writer = csv.writer(new_csv)\n",
    "    csv_writer.writerow([\"Frame Number\", \"Detections (x1 x2 y1 y2 class conf id)\"])\n",
    "    for line in csv_array_3:\n",
    "      csv_writer.writerow(line)\n",
    "#print(\"Done, time since start:\", time.time() - start_time)\n",
    "\n",
    "# Prints a summary of detections\n",
    "for video in summary:\n",
    "  print(video)\n",
    "  for id in summary[video]:\n",
    "    if not summary[video][id] == \"urdbl\":\n",
    "      print(f\"id: {id} \\tlabel: {summary[video][id]}\")\n",
    "#print(\"Done, time since start:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vpqw2q4u5m9U"
   },
   "source": [
    "## Using OCR to identify text on signs\n",
    "Loops through csv to apply EasyOCR to signs and applies speed number to class to signs grouped by id\n",
    "\n",
    "Any signs unable to be read will be overwritten as \"urdbl\"\n",
    "\n",
    "Run the processing before this, as this overwrites label classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9YvZ5vNT5qjZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "20191222_171147_EF.mp4\n",
      "{'3': ['6', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '65', '55', '51', '65', '51', '55', '65', '55', '65', '55', '65']}\n",
      "3 {'65': 23, '55': 4, 'urdbl': 0}\n",
      "27 detections out of 54 frames\n",
      "{'3': '65'}\n",
      "===========================================================================\n",
      "20191222_171147_EF.mp4\n",
      "id: 3 \tlabel: 65\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import time\n",
    "\n",
    "easy_reader = easyocr.Reader(['en'])\n",
    "\n",
    "summary = {}\n",
    "\n",
    "# Only iterates through working video directory, not all processed videos\n",
    "\n",
    "for video_name in os.listdir(video_output_path):\n",
    "  if not video_name in os.listdir(videos_path):\n",
    "    continue\n",
    "\n",
    "  summary[video_name] = {}\n",
    "  print(\"\\n\\n\\n\" + video_name)\n",
    "  video_path = os.path.join(video_output_path, video_name)\n",
    "  labels_path = os.path.join(video_path, \"labels.csv\")\n",
    "\n",
    "\n",
    "  # Open labels csv from video\n",
    "  csv_array = []\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    csv_array = list(csv_reader)\n",
    "    header = csv_array.pop(0)\n",
    "  \n",
    "  source_video_path = os.path.join(videos_path, video_name)\n",
    "  reader = cv2.VideoCapture(source_video_path)\n",
    "  total_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "  stops_by_id = {}\n",
    "  speeds_by_id = {}\n",
    "  id_count = {}\n",
    "  for row in csv_array:\n",
    "    if len(row) > 1:\n",
    "      for raw_data in row[1:]:\n",
    "        d = raw_data.split(\";\")\n",
    "        frame_number = int(row[0])\n",
    "        if frame_number < total_frames:\n",
    "          reader.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "          success, img = reader.read()\n",
    "          if d[6] not in id_count:\n",
    "            id_count[d[6]] = 0\n",
    "          id_count[d[6]] += 1\n",
    "\n",
    "          # Block for speed limits, reads number and overwrites label\n",
    "          if success and d[4] == \"speedLimit\":\n",
    "            # Cropping only the sign\n",
    "            cropped_img = img[int(d[2]):int(d[3]), int(d[0]):int(d[1]), :].copy()\n",
    "            thresh = preprocess(cropped_img)\n",
    "\n",
    "            pil_img = Image.fromarray(thresh)\n",
    "            easy_detections = easy_reader.readtext(np.array(pil_img))\n",
    "            #cv2_imshow(np.array(pil_img))\n",
    "\n",
    "            # Gathers only the numbers over a confidence threshold\n",
    "            numbers = [] # Array to store all numbers from a single frame of detections\n",
    "            for detect in easy_detections:\n",
    "              if detect[2] >= ocr_conf_threshold:\n",
    "                for c in detect[1]:\n",
    "                  if c.isdigit():\n",
    "                    numbers.append(c)\n",
    "\n",
    "            # Prunes the numbers since speed limits are generally at most 2 digits\n",
    "            while len(numbers) > 2 or (len(numbers) > 0 and numbers[0] == \"0\"):\n",
    "                numbers.pop(0)\n",
    "            numbers = \"\".join(numbers) # Converts list of numbers to string\n",
    "            if len(numbers) == 2 or len(numbers) == 1:\n",
    "              if d[6] not in speeds_by_id:\n",
    "                speeds_by_id[d[6]] = []\n",
    "              speeds_by_id[d[6]].append(numbers) # Append to a dictionary of numbers categorized by group ID\n",
    "\n",
    "          # Block for stop signs, reads to make sure stop signs are stop signs\n",
    "          elif success and d[4] == \"stop\":\n",
    "            cropped_img = img[int(d[2]):int(d[3]), int(d[0]):int(d[1]), :].copy()\n",
    "            thresh = preprocess(cropped_img)\n",
    "            pil_img = Image.fromarray(thresh)\n",
    "            easy_detections = easy_reader.readtext(np.array(pil_img))\n",
    "            #print(d[6], easy_detections)\n",
    "            if not d[6] in stops_by_id.keys():\n",
    "              stops_by_id[d[6]] = 0\n",
    "            for detection in easy_detections:\n",
    "              if \"stop\" in detection[1].lower():\n",
    "                stops_by_id[d[6]] += 1\n",
    "\n",
    "  # Speed limits\n",
    "  # Out of the detections in one group, picks the most frequent for the entire group\n",
    "  likely_speeds = {}\n",
    "  print(speeds_by_id)\n",
    "  for id in speeds_by_id:\n",
    "    number_of_speeds = {}\n",
    "    for speed in speeds_by_id[id]:\n",
    "\n",
    "      # Speed limit numbers are almost always ending in 5 or 0 (ex. 15, 70, 60)\n",
    "      if len(speed) == 2 and speed[-1] in [\"0\", \"5\"]:\n",
    "        if speed not in number_of_speeds:\n",
    "          number_of_speeds[speed] = 0\n",
    "        number_of_speeds[speed] += 1\n",
    "\n",
    "    # Sometimes misses the 2nd digit\n",
    "    for speed in speeds_by_id[id]:\n",
    "      if len(speed) == 1:\n",
    "        for i in range(len(number_of_speeds)):\n",
    "          if speed in list(number_of_speeds.keys())[i][0]:\n",
    "            number_of_speeds[list(number_of_speeds.keys())[i]] += 1\n",
    "\n",
    "    number_of_speeds[\"urdbl\"] = 0\n",
    "    print(id, number_of_speeds)\n",
    "    detections_made = 0\n",
    "    for speed_count in number_of_speeds:\n",
    "      detections_made += number_of_speeds[speed_count]\n",
    "    print(f\"{detections_made} detections out of {id_count[id]} frames\")\n",
    "\n",
    "    # Ignore grouping if below detections threshold\n",
    "    if detections_made / id_count[id] <= ocr_detections_threshold:\n",
    "      likely_speeds[id] = \"urdbl\"\n",
    "    else:\n",
    "      likely_speeds[id] = max(number_of_speeds, key=number_of_speeds.get)\n",
    "\n",
    "    for id in likely_speeds:\n",
    "      if likely_speeds[id] != \"urdbl\":\n",
    "        summary[video_name][id] = likely_speeds[id]\n",
    "    \n",
    "  # Save to CSV\n",
    "  with open(labels_path, \"w\", newline='') as labels_csv:\n",
    "    csv_writer = csv.writer(labels_csv)\n",
    "    csv_writer.writerow(header)\n",
    "    for row in csv_array:\n",
    "      for i in range(len(row)):\n",
    "        detection = row[i].split(\";\")\n",
    "        if len(detection) == 7:\n",
    "\n",
    "          # Overwrites for speed limits\n",
    "          if detection[6] in likely_speeds:\n",
    "            detection[4] = f\"{detection[4]} ({likely_speeds[detection[6]]})\"\n",
    "            row[i] = f\"{detection[0]};{detection[1]};{detection[2]};{detection[3]};{detection[4]};{detection[5]};{detection[6]}\"\n",
    "            break\n",
    "\n",
    "          # Overwrites for stop signs\n",
    "          elif detection[6] in stops_by_id.keys():\n",
    "            if stops_by_id[detection[6]] >= id_count[detection[6]] * 0.05:\n",
    "              if not detection[6] in summary[video_name]:\n",
    "                summary[video_name][detection[6]] = \"stop\"\n",
    "            else:\n",
    "              row[i] = f\"{detection[0]};{detection[1]};{detection[2]};{detection[3]};urdbl;{detection[5]};{detection[6]}\"\n",
    "\n",
    "      csv_writer.writerow(row)\n",
    "  print(likely_speeds)\n",
    "  print(\"===========================================================================\")\n",
    "\n",
    "  \n",
    "  reader.release()\n",
    "\n",
    "# Prints a summary of detections\n",
    "for video in summary:\n",
    "  print(video)\n",
    "  for id in summary[video]:\n",
    "    if not summary[video][id] == \"urdbl\":\n",
    "      print(f\"id: {id} \\tlabel: {summary[video][id]}\")\n",
    "#print(\"Done, time since start:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXc_7nLZ19Q7"
   },
   "source": [
    "##Create video clips highlighting only detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RonO_r8T18ag"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "if not os.path.exists(video_snippets_path):\n",
    "  os.mkdir(video_snippets_path)\n",
    "\n",
    "for video_name in os.listdir(videos_path):\n",
    "  if not video_name in os.listdir(video_output_path):\n",
    "    continue\n",
    "  \n",
    "  specific_video_folder_path = os.path.join(video_output_path, video_name)\n",
    "  labels_path = os.path.join(specific_video_folder_path, \"labels.csv\")\n",
    "  source_video_path = os.path.join(videos_path, video_name)\n",
    "\n",
    "  print(source_video_path)\n",
    "\n",
    "  # Gets video resolution and fps from source\n",
    "  reader = cv2.VideoCapture(source_video_path)\n",
    "  reader2 = False\n",
    "  if snippet_interior:\n",
    "    snippet_interior_name = \".\".join(video_name.split(\".\")[:-1])\n",
    "    if snippet_interior_name[-1] == \"F\":\n",
    "      snippet_interior_name = snippet_interior_name[:-1] + \"R\"\n",
    "      #print(snippet_interior_name + \".mp4\")\n",
    "      #print(os.listdir(videos_path))\n",
    "      if snippet_interior_name + \".mp4\" in os.listdir(videos_path):\n",
    "        interior_source_path = os.path.join(videos_path, snippet_interior_name + \".mp4\")\n",
    "        reader2 = cv2.VideoCapture(interior_source_path)\n",
    "\n",
    "\n",
    "\n",
    "  video_res = [int(reader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(reader.get(cv2.CAP_PROP_FRAME_HEIGHT)), math.ceil(reader.get(cv2.CAP_PROP_FPS)), int(reader.get(cv2.CAP_PROP_FRAME_COUNT))]\n",
    "  if snippet_interior and reader2:\n",
    "    video_res2 = (int(reader2.get(cv2.CAP_PROP_FRAME_WIDTH)), int(reader2.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "  fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "  \n",
    "\n",
    "  # Reads from processed CSV\n",
    "  csv_array = []\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    csv_array = list(csv_reader)\n",
    "    header = csv_array.pop(0)\n",
    "\n",
    "   # Groups detections by ID\n",
    "  labels_by_id = {}\n",
    "  # {id: [label_class, start_time, end_time]}\n",
    "  for line in csv_array:\n",
    "    if len(line) > 1:\n",
    "      frame = int(line[0])\n",
    "      for detection in line:\n",
    "        d = detection.split(\";\")\n",
    "        if len(d) == 7:\n",
    "          labelclass = d[4]\n",
    "          id = d[6]\n",
    "\n",
    "          #if \"urdbl\" in labelclass or labelclass == \"speedLimit\":\n",
    "          #  continue\n",
    "\n",
    "          # Create list for id if not already existing\n",
    "          if not id in labels_by_id:\n",
    "            labels_by_id[id] = [labelclass, frame, frame] # [labelclass, earliest_frame, latest_frame]\n",
    "          # Finds the max and min for frame count per ID\n",
    "          labels_by_id[id][1] = min(labels_by_id[id][1], frame)\n",
    "          labels_by_id[id][2] = max(labels_by_id[id][2], frame)\n",
    "\n",
    "  print(labels_by_id)\n",
    "  for id in labels_by_id:\n",
    "    video_name_cut = \".\".join(video_name.split(\".\")[:-1])\n",
    "    \n",
    "    snippets_directory = video_snippets_path\n",
    "    if snippet_split_classes:\n",
    "      if \"stop\" in labels_by_id[id][0]:\n",
    "        snippets_directory = os.path.join(snippets_directory, \"stop\")\n",
    "      else:\n",
    "        snippets_directory = os.path.join(snippets_directory, \"speed_limit\")\n",
    "      if not (os.path.exists(snippets_directory) and os.path.isdir(snippets_directory)):\n",
    "        os.mkdir(snippets_directory)\n",
    "    specific_snippet_path = os.path.join(snippets_directory, f\"{video_name_cut}_{labels_by_id[id][0]}_{id}.mp4\")\n",
    "    print(specific_snippet_path)\n",
    "    print(video_res)\n",
    "\n",
    "    # Adding buffer to snippet\n",
    "    earliest_frame = max(labels_by_id[id][1] - (snippet_buffer * video_res[2]), 0)\n",
    "    latest_frame = min(labels_by_id[id][2] + (snippet_buffer * video_res[2]), video_res[3] - 1)\n",
    "\n",
    "    success = True\n",
    "\n",
    "    # start frame\n",
    "    frame_count = earliest_frame\n",
    "\n",
    "    video_writer = cv2.VideoWriter(specific_snippet_path, fourcc, video_res[2], (video_res[0], video_res[1]))\n",
    "\n",
    "    if snippet_interior and reader2:\n",
    "      snippet_interior_path = os.path.join(snippets_directory, f\"{snippet_interior_name}_{labels_by_id[id][0]}_{id}.mp4\")\n",
    "      print(\"writing\", snippet_interior_path)\n",
    "      video_writer2 = cv2.VideoWriter(snippet_interior_path, fourcc, video_res[2], video_res2)\n",
    "      reader2.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "\n",
    "    reader.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "    while success and frame_count <= latest_frame:\n",
    "      success, frame = reader.read()\n",
    "\n",
    "      if snippet_interior and reader2:\n",
    "        success2, frame2 = reader2.read()\n",
    "        if success2:\n",
    "          video_writer2.write(frame2)\n",
    "\n",
    "      for detection in csv_array[frame_count][1:]:\n",
    "        detection = detection.split(\";\")\n",
    "\n",
    "        # Cases where bounding box isn't drawn\n",
    "        if len(detection) != 6 and len(detection) != 7:\n",
    "          continue\n",
    "        #if detection[4] == \"speedLimit\":\n",
    "        #  continue\n",
    "\n",
    "        if id != detection[6]:\n",
    "          continue\n",
    "\n",
    "        \n",
    "        # Draw boxes around detections\n",
    "        tl = round(0.002 * (frame.shape[0] + frame.shape[1]) / 2) + 1\n",
    "        c1, c2 = (int(detection[0]), int(detection[2])), (int(detection[1]), int(detection[3]))\n",
    "        cv2.rectangle(frame, c1, c2, (128, 128, 128), thickness=tl, lineType=cv2.LINE_AA)\n",
    "        if detection[4]:\n",
    "          tf = max(tl - 1, 1)\n",
    "          label_text = detection[4]\n",
    "          if len(detection) > 6:\n",
    "            label_text += f\" id: {detection[6]}\"\n",
    "          t_size = cv2.getTextSize(label_text, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "          c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "          cv2.rectangle(frame, c1, c2, (128, 128, 128), -1, cv2.LINE_AA)\n",
    "          cv2.putText(frame, label_text, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "      frame_count += 1\n",
    "      video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "    if snippet_interior and reader2:\n",
    "      video_writer2.release()\n",
    "  reader.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyWacJZsS0S7"
   },
   "source": [
    "## Create results CSV\n",
    "Creates a readable results CSV\n",
    ">label class, start time, end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJ-nZbOwI66u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "if results_output_path:\n",
    "  if not os.path.exists(results_output_path):\n",
    "    os.mkdir(results_output_path)\n",
    "\n",
    "for video_name in os.listdir(videos_path):\n",
    "  video_path = os.path.join(videos_path, video_name)\n",
    "\n",
    "  if not (os.path.exists(video_path) and not os.path.isdir(video_path) and video_name.endswith(\".mp4\")):\n",
    "    continue\n",
    "  print(video_name)\n",
    "  \n",
    "  video_processed_path = os.path.join(video_output_path, video_name)\n",
    "  results_path = os.path.join(video_processed_path, \"results.csv\")\n",
    "  # Writes to processed folder\n",
    "  if os.path.exists(video_processed_path) and os.path.isdir(video_processed_path):\n",
    "    with open(results_path, \"w\", newline='') as results_csv:\n",
    "      csv_writer = csv.writer(results_csv)\n",
    "      csv_writer.writerow([\"Label class\", \"ID\", \"Start time\", \"End time\", \"Mean Confidence\", \"Start datetime\", \"End datetime\"])\n",
    "\n",
    "  # Writes to results folder if it exists\n",
    "  if results_output_path and \"F.mp4\" in video_name:\n",
    "    results_output_video_path = os.path.join(results_output_path, video_name + \".csv\")\n",
    "    with open(results_output_video_path, \"w\", newline='') as results_csv:\n",
    "      csv_writer = csv.writer(results_csv)\n",
    "      csv_writer.writerow([\"Label class\", \"ID\", \"Start time\", \"End time\", \"Mean Confidence\", \"Start datetime\", \"End datetime\"])\n",
    "      \n",
    "\n",
    "# Creates a list of all snippet files\n",
    "if results_snippets_sync and os.path.exists(video_snippets_path):\n",
    "  all_items = os.listdir(video_snippets_path)\n",
    "\n",
    "  stop_snippets = os.path.join(video_snippets_path, \"stop\")\n",
    "  if os.path.exists(stop_snippets) and os.path.isdir(stop_snippets):\n",
    "      all_items += os.listdir(stop_snippets)\n",
    "\n",
    "  speed_snippets = os.path.join(video_snippets_path, \"speed_limit\")\n",
    "  if os.path.exists(speed_snippets) and os.path.isdir(speed_snippets):\n",
    "      all_items += os.listdir(speed_snippets)\n",
    "\n",
    "  # Acquires name and ID from snippets and adds to dictionary\n",
    "  video_id = {}\n",
    "  for item in all_items:\n",
    "    if not os.path.isdir(item):\n",
    "      if item.endswith(\".mp4\"):\n",
    "        video_name = \"_\".join(item.split(\"_\")[:-2]) + \".mp4\"\n",
    "        id = item.split(\"_\")[-1].split(\".\")[0]\n",
    "        if not video_name in video_id:\n",
    "          video_id[video_name] = []\n",
    "        if id.isnumeric():\n",
    "          video_id[video_name].append(id)\n",
    "  dir = video_id\n",
    "elif os.path.exists(videos_path):\n",
    "  dir = [video for video in os.listdir(videos_path) if (not os.path.isdir(os.path.join(videos_path, video)) and video.endswith(\"F.mp4\"))]\n",
    "else:\n",
    "  dir = []\n",
    "print(dir)\n",
    "\n",
    "# iterates through list of videos\n",
    "for video_name in dir:\n",
    "  #print(video_name)\n",
    "  if not video_name in os.listdir(video_output_path):\n",
    "    continue\n",
    "  \n",
    "  source_video_path = os.path.join(videos_path, video_name)\n",
    "\n",
    "  # Get FPS from source video\n",
    "  reader = cv2.VideoCapture(source_video_path)\n",
    "  source_fps = reader.get(cv2.CAP_PROP_FPS)\n",
    "  reader.release()\n",
    "\n",
    "  curr_video_path = os.path.join(video_output_path, video_name)\n",
    "\n",
    "  csv_array = []\n",
    "  \n",
    "  # Copies csv to a list\n",
    "  labels_path = os.path.join(curr_video_path, \"labels.csv\")\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    csv_array = list(csv_reader)\n",
    "    header = csv_array.pop(0)\n",
    "  \n",
    "  # Groups detections by ID\n",
    "  labels_by_id = {}\n",
    "  # {id: [label_class, start_time, end_time]}\n",
    "  confidence_by_id = {}\n",
    "  # {id: [confidence_frame1, confidence_frame2, ...]}\n",
    "  for line in csv_array:\n",
    "    if len(line) > 1:\n",
    "      frame = int(line[0])\n",
    "      for detection in line:\n",
    "        d = detection.split(\";\")\n",
    "        if len(d) == 7:\n",
    "          labelclass = d[4]\n",
    "          conf = float(d[5])\n",
    "          id = d[6]\n",
    "\n",
    "          #if \"urdbl\" in labelclass or labelclass == \"speedLimit\":\n",
    "          #  continue\n",
    "\n",
    "          # Create list for id if not already existing\n",
    "          if not id in labels_by_id:\n",
    "            labels_by_id[id] = [labelclass, frame, frame] # [labelclass, earliest_frame, latest_frame]\n",
    "          # Finds the max and min for frame count per ID\n",
    "          labels_by_id[id][1] = min(labels_by_id[id][1], frame)\n",
    "          labels_by_id[id][2] = max(labels_by_id[id][2], frame)\n",
    "\n",
    "          if not id in confidence_by_id:\n",
    "            confidence_by_id[id] = []\n",
    "          confidence_by_id[id].append(conf)\n",
    "\n",
    "  print(\"\\n\" + video_name)\n",
    "  print(labels_by_id)\n",
    "\n",
    "\n",
    "  # Writes detections by ID\n",
    "  results_path = os.path.join(curr_video_path, \"results.csv\")\n",
    "  #print(results_path)\n",
    "  with open(results_path, \"w\", newline='') as results_csv:\n",
    "    csv_writer = csv.writer(results_csv)\n",
    "    csv_writer.writerow([\"Label class\", \"ID\", \"Start time\", \"End time\", \"Mean Confidence\", \"Start datetime\", \"End datetime\"])\n",
    "    #print(labels_by_id)\n",
    "    for id in labels_by_id:\n",
    "      d = labels_by_id[id]\n",
    "      label_class = d[0]\n",
    "      start_seconds = int(d[1] / source_fps)\n",
    "      end_seconds = int(d[2] / source_fps)\n",
    "\n",
    "      name_split = video_name.split(\"_\")\n",
    "      video_date = name_split[0]\n",
    "      video_time = name_split[1]\n",
    "\n",
    "      year = int(video_date[0:4])\n",
    "      month = int(video_date[4:6])\n",
    "      day = int(video_date[6:8])\n",
    "\n",
    "      hour = int(video_time[0:2])\n",
    "      minute = int(video_time[2:4])\n",
    "      second = int(video_time[4:6])\n",
    "\n",
    "      csv_start_time = str(datetime.timedelta(seconds=start_seconds))\n",
    "      csv_start_time2 = datetime.datetime(year, month, day, hour=hour, minute=minute, second=second) + datetime.timedelta(seconds=start_seconds)\n",
    "\n",
    "      csv_end_time = str(datetime.timedelta(seconds=end_seconds))\n",
    "      csv_end_time2 = datetime.datetime(year, month, day, hour=hour, minute=minute, second=second) + datetime.timedelta(seconds=end_seconds)\n",
    "\n",
    "      mean_confidence = sum(confidence_by_id[id]) / len(confidence_by_id[id])\n",
    "      new_row = [label_class, id, csv_start_time, csv_end_time, mean_confidence, csv_start_time2, csv_end_time2]\n",
    "\n",
    "      if results_snippets_sync:\n",
    "        if id in dir[video_name]:\n",
    "          print(new_row)\n",
    "          csv_writer.writerow(new_row)\n",
    "      else:\n",
    "        print(new_row)\n",
    "        csv_writer.writerow(new_row)\n",
    "  if results_output_path:\n",
    "    #print(results_path, os.path.join(results_output_path, video_name + \".csv\"))\n",
    "\n",
    "    shutil.copy(results_path, os.path.join(results_output_path, video_name + \".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaKOnD6znGce"
   },
   "source": [
    "##Show classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Faam4f-4nB7o"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "summary = {}\n",
    "\n",
    "# Only iterates through working video directory, not all processed videos\n",
    "\n",
    "for video_name in os.listdir(video_output_path):\n",
    "  if not video_name in os.listdir(videos_path):\n",
    "    continue\n",
    "\n",
    "  summary[video_name] = {}\n",
    "  print(\"\\n\\n\\n\" + video_name)\n",
    "  video_path = os.path.join(video_output_path, video_name)\n",
    "  labels_path = os.path.join(video_path, \"labels.csv\")\n",
    "\n",
    "\n",
    "  # Open labels csv from video\n",
    "  csv_array = []\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    csv_array = list(csv_reader)\n",
    "    header = csv_array.pop(0)\n",
    "  \n",
    "  source_video_path = os.path.join(videos_path, video_name)\n",
    "  reader = cv2.VideoCapture(source_video_path)\n",
    "  total_frames = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "  \n",
    "\n",
    "# Prints a summary of detections\n",
    "for video in summary:\n",
    "  print(video)\n",
    "  for id in summary[video]:\n",
    "    if not summary[video][id] == \"urdbl\":\n",
    "      print(f\"id: {id} \\tlabel: {summary[video][id]}\")\n",
    "#print(\"Done, time since start:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cflx222vjPh3"
   },
   "source": [
    "## Create a video with bounding boxes based on labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dc2ujPuAWDpJ"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "for video_name in os.listdir(videos_path):\n",
    "  if not video_name in os.listdir(video_output_path):\n",
    "    continue\n",
    "  print(video_name)\n",
    "  labels_path = f\"{video_output_path}{video_name}/labels.csv\"\n",
    "  videos_write_path = f\"{video_output_path}{video_name}/{video_name}\"\n",
    "\n",
    "  # Preserves original video format \n",
    "  filetypes = [\".mp4\", \".MP4\", \".avi\"]\n",
    "  if not any(filetype in video_name for filetype in filetypes):\n",
    "    videos_write_path += \".mp4\"\n",
    "\n",
    "  # Reads from processed CSV\n",
    "  csv_array = []\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    header = next(csv_reader, None)\n",
    "    for line in csv_reader:\n",
    "      csv_array.append(line)\n",
    "\n",
    "  # Gets video resolution and fps from source\n",
    "  reader = cv2.VideoCapture(videos_path + video_name)\n",
    "  video_res = [int(reader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(reader.get(cv2.CAP_PROP_FRAME_HEIGHT)), reader.get(cv2.CAP_PROP_FPS)]\n",
    "  fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "  writer = cv2.VideoWriter(videos_write_path, fourcc, video_res[2], (video_res[0], video_res[1]))\n",
    "  \n",
    "  success = True\n",
    "  frame_count = 0\n",
    "  while success:\n",
    "    success, frame = reader.read()\n",
    "    if success:\n",
    "      if(frame_count < len(csv_array) and len(csv_array[frame_count]) > 1):\n",
    "        for detection in csv_array[frame_count][1:]:\n",
    "          detection = detection.split(\";\")\n",
    "\n",
    "          # Cases where bounding box isn't drawn\n",
    "          if len(detection) != 6 and len(detection) != 7:\n",
    "            continue\n",
    "          if detection[4] == \"speedLimit\":\n",
    "            continue\n",
    "          if \"urdbl\" in detection[4]:\n",
    "            continue\n",
    "\n",
    "          # Draw boxes around detections\n",
    "          tl = round(0.002 * (frame.shape[0] + frame.shape[1]) / 2) + 1\n",
    "          c1, c2 = (int(detection[0]), int(detection[2])), (int(detection[1]), int(detection[3]))\n",
    "          cv2.rectangle(frame, c1, c2, (128, 128, 128), thickness=tl, lineType=cv2.LINE_AA)\n",
    "          if detection[4]:\n",
    "            tf = max(tl - 1, 1)\n",
    "            label_text = detection[4]\n",
    "            if len(detection) > 6:\n",
    "              label_text += f\" id: {detection[6]}\"\n",
    "            t_size = cv2.getTextSize(label_text, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "            cv2.rectangle(frame, c1, c2, (128, 128, 128), -1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, label_text, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "      frame_count += 1\n",
    "      writer.write(frame)\n",
    "  writer.release()\n",
    "  reader.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pOkGLv1dMqh"
   },
   "source": [
    "Train a YOLOv5s model starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
    "\n",
    "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [],
   "source": [
    "# Tensorboard  (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t2ZFghoa3Km"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVG89ROCMYAP"
   },
   "outputs": [],
   "source": [
    "# hyperparameter evolution\n",
    "!python train.py --img 640 --batch 16 --epochs 10 --data lisa.yaml --weights \"./yolov5x.pt\" --evolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NcFxRcFdJ_O"
   },
   "outputs": [],
   "source": [
    "\n",
    "!python train.py --img 640 --batch 16 --epochs 200 --data lisa.yaml --weights \"./yolov5l.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r4q8GBvNuIE"
   },
   "outputs": [],
   "source": [
    "!python train.py --resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mAHBhPabIqm"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oWgUv2Soqdn"
   },
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsS_gjyqrqrY"
   },
   "source": [
    "Prints out class names of all proccessed videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf3VMtgYopin"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "for video_name in os.listdir(video_output_path):\n",
    "  labels_path = f\"{video_output_path}{video_name}/labels.csv\"\n",
    "  csv_array = []\n",
    "  with open(labels_path, \"r\") as labels_csv:\n",
    "    csv_reader = csv.reader(labels_csv)\n",
    "    header = next(csv_reader, None)\n",
    "    for line in csv_reader:\n",
    "      csv_array.append(line)\n",
    "  types_by_id = {}\n",
    "  for line in csv_array:\n",
    "    for detection in line:\n",
    "      d = detection.split(\";\")\n",
    "      if len(d) < 5:\n",
    "        continue\n",
    "      classname = d[4]\n",
    "      if classname == \"urdbl\" in classname:\n",
    "        continue\n",
    "      id = d[6]\n",
    "      if not id in types_by_id:\n",
    "        types_by_id[id] = classname\n",
    "  print(video_name)\n",
    "  classes = \"\"\n",
    "  for id in types_by_id:\n",
    "    classes += \" \" + types_by_id[id]\n",
    "  print(classes, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKMrf2JIrt7z"
   },
   "source": [
    "Copy only videos from processed videos to specified folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBM2ugaJrtek"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "folder_to_copy_to = \"../sample 2/\"\n",
    "\n",
    "folder_found = True\n",
    "if os.path.exists(folder_to_copy_to) and os.path.isdir(folder_to_copy_to):\n",
    "  print(\"Starting copy\")\n",
    "else:\n",
    "  print(\"Folder not found\")\n",
    "  folder_found = False\n",
    "\n",
    "if folder_found:\n",
    "  for video_name in os.listdir(video_output_path):\n",
    "    for file in os.listdir(video_output_path + video_name):\n",
    "      if file[-3:].lower() == \"mp4\":\n",
    "        print(\"Copying\", file)\n",
    "        shutil.copyfile(f\"{video_output_path}{video_name}/{file}\", f\"{folder_to_copy_to}{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WPvRbS5Swl6"
   },
   "source": [
    "## Local Logging\n",
    "\n",
    "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and val jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riPdhraOTCO0"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/train/exp/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels\n",
    "Image(filename='runs/train/exp/test_batch0_labels.jpg', width=800)  # val batch 0 labels\n",
    "Image(filename='runs/train/exp/test_batch0_pred.jpg', width=800)  # val batch 0 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYG4WFEnTVrI"
   },
   "source": [
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931219-48bf8700-e002-11eb-84f0-e05d95b118dd.jpg\" width=\"700\">  \n",
    "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931217-4826f080-e002-11eb-87b9-ae0925a8c94b.jpg\" width=\"700\">  \n",
    "`test_batch0_labels.jpg` shows val batch 0 labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931209-46f5c380-e002-11eb-9bd5-7a3de2be9851.jpg\" width=\"700\">  \n",
    "`test_batch0_pred.jpg` shows val batch 0 _predictions_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training results are automatically logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and `runs/train/exp/results.txt`, which is plotted as `results.png` (below) after training completes. You can also plot any `results.txt` file manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDznIqPF7nk3"
   },
   "outputs": [],
   "source": [
    "from utils.plots import plot_results \n",
    "plot_results(save_dir='runs/train/exp')  # plot all results*.txt files in 'runs/train/exp'\n",
    "Image(filename='runs/train/exp/results.png', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfrEegCSW3fK"
   },
   "source": [
    "<p align=\"left\"><img width=\"800\" alt=\"COCO128 Training Results\" src=\"https://user-images.githubusercontent.com/26833433/125273596-6300aa00-e30d-11eb-8dc4-70a960c53013.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qu7Iesl0p54"
   },
   "source": [
    "# Status\n",
    "\n",
    "![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)\n",
    "\n",
    "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "F-Ufi8RS_LQq",
    "xQOqLPRTo8eR",
    "Vpqw2q4u5m9U",
    "Cflx222vjPh3"
   ],
   "name": "Sign Detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
